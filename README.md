
# Intrusion-Detection-on-UNSBW-NB15-by-using-Machine-Learning-Techniques
Since the world prepares to enter fifth-generation communication technology and embrace concepts like virtualization and cloudification, the most important factor to consider is” security,” This project depicts a paradigm for calculating numerous data parameters in a network, such as accuracy, precision, and confusion matrix, among others. The overall goal is to have a better understanding of data integrity and improve data prediction accuracy. By doing so, the quantity of malicious material floating around in a network may be reduced, making it a safer place to share data.
## dataset 
This dataset has nine types of attacks, namely, Fuzzers, Analysis, Backdoors, DoS, Exploits, Generic, Reconnaissance, Shellcode and Worms. The Argus, Bro-IDS tools are used and twelve algorithms are developed to generate totally 49 features with the class label. These features are described in [UNSW-NB15_features.csv](https://archive.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/NUSW-NB15_features.csv) file. as shown in the following figure 1
![Data Distribution](https://github.com/eslamahmed235/Intrusion-Detection-on-UNSBW-NB15-by-using-Machine-Learning-Techniques/blob/main/data/Data%20Distribution.png)

## For our methodology,
 we chose XGBoost, Decision Tree, Random Forest, and an ensemble technique called “Stacking”, we used stacking with all models. From previous research papers, we found that the best results obtained with the UNSBW-NB15 dataset used tree-based models such as Decision Tree, Random Forest, and XGBoost, among others. We wanted to try a new technique with these models that was not used in the previous research, so we used an ensemble technique called the “Stacking” technique.  <br/>
We found that the data was imbalanced, and we tried many sampling techniques but all of them will damage the data, not solve the problem because the count of class was so different. so, we thought to make two models, one for the binary class (Normal, Abnormal) and one for multi classes of attacks as in Fig.3. Finally, we merge the two results as in Fig.4.  <br/>
![multi stacking](https://github.com/eslamahmed235/Intrusion-Detection-on-UNSBW-NB15-by-using-Machine-Learning-Techniques/blob/main/data/Picture1.png)
![Methodology](https://github.com/eslamahmed235/Intrusion-Detection-on-UNSBW-NB15-by-using-Machine-Learning-Techniques/blob/main/data/Picture2.png) <br/>
**Models descriptions:** A decision tree is a machine learning model algorithm that partitions the data into subsets. The partitioning process starts with a binary split and continues until no further splits can be made. Variable lengths are formed. It is also used for regression problems and classification problems. Random forest is a machine learning model algorithm that is also used in classification and regression problems. It builds decision trees on different samples. <br/>
The XGBoost algorithm is a gradient boosting algorithm, a common technique in ensemble learning. It has some features like execution speed and model performance. Stacking is an ensemble machine learning algorithm. It uses a meta-learning algorithm to learn how to best combine the predictions from two or more base machine learning algorithms. We used a stacking algorithm to combine the Decision tree, Random Forest and XGBoost <br/>
**for evaluation** we start training the models with the train dataset and the validation dataset for the binary and multi classes problems to found best one of the four models to be used on testing, as you can see the results for all stages in the following Table. <br/>
![ ](https://github.com/eslamahmed235/Intrusion-Detection-on-UNSBW-NB15-by-using-Machine-Learning-Techniques/blob/main/data/result.png)
